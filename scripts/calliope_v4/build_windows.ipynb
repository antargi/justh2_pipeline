{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa66a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f6616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_HOURS = 24 * 7  # 7 días\n",
    "STEP_HOURS = 24 * 3    # stride de 3 días (puedes cambiar)\n",
    "EPS = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f43e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _idx_to_str(index_like):\n",
    "    if hasattr(index_like, \"to_pandas\"):\n",
    "        index_like = index_like.to_pandas()\n",
    "    if isinstance(index_like, pd.MultiIndex):\n",
    "        return index_like.map(lambda tpl: '::'.join(map(str, tpl))).astype(str)\n",
    "    return pd.Index(index_like).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b841aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sum_sel(da, dim_name, mask_func):\n",
    "    labels = _idx_to_str(da[dim_name])\n",
    "    sel_labels = labels[mask_func(labels)].tolist()\n",
    "    if dim_name in da.dims and sel_labels:\n",
    "        return float(da.sel({dim_name: sel_labels}).sum())\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a1a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _series_time(da, dim_name, mask_func):\n",
    "    labels = _idx_to_str(da[dim_name])\n",
    "    sel_labels = labels[mask_func(labels)].tolist()\n",
    "    if dim_name in da.dims and sel_labels:\n",
    "        ts = da.sel({dim_name: sel_labels}).sum(dim=dim_name)  # suma sobre loc_tech_carriers...\n",
    "        return ts\n",
    "    # devolver zeros con las mismas horas si no hay\n",
    "    return xr.zeros_like(da.isel({dim_name: 0}, drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb57ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _energy_cap(ds, pat):\n",
    "    s = ds.energy_cap.to_series()\n",
    "    if s.empty: return 0.0\n",
    "    idx = _idx_to_str(s.index).str.contains(pat)\n",
    "    return float(s[idx].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e7dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _storage_cap(ds, pat):\n",
    "    s = ds.storage_cap.to_series() if 'storage_cap' in ds else pd.Series(dtype=float)\n",
    "    if s.empty: return 0.0\n",
    "    idx = _idx_to_str(s.index).str.contains(pat)\n",
    "    return float(s[idx].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac64d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cost_sum(ds, pat):\n",
    "    s = ds.cost.to_series() if 'cost' in ds else pd.Series(dtype=float)\n",
    "    if s.empty: return 0.0\n",
    "    idx = _idx_to_str(s.index).str.contains(pat)\n",
    "    return float(s[idx].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d75dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _window_slices(nT, win, step):\n",
    "    starts = list(range(0, max(1, nT - win + 1), step))\n",
    "    if not starts or (starts[-1] + win < nT):\n",
    "        starts.append(max(0, nT - win))\n",
    "    return [(s, s + win) for s in starts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70bb216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_windows(nc_path: str, out_parquet: str):\n",
    "    ds = xr.load_dataset(nc_path)\n",
    "\n",
    "    # --- Series temporales clave ---\n",
    "    da_con  = ds.carrier_con\n",
    "    da_prod = ds.carrier_prod\n",
    "\n",
    "    # Demanda H2 servida (convención: demand_* en con, portador hydrogen; suele ser negativa)\n",
    "    h2_dem_con_ts = _series_time(\n",
    "        da_con, 'loc_tech_carriers_con',\n",
    "        lambda lab: lab.str.endswith('::hydrogen') & lab.str.contains('demand_h2')\n",
    "    )\n",
    "    h2_served_ts = -1.0 * h2_dem_con_ts  # positivizamos\n",
    "\n",
    "    # Producción H2 (electrolizador)\n",
    "    h2_prod_ts = _series_time(\n",
    "        da_prod, 'loc_tech_carriers_prod',\n",
    "        lambda lab: lab.str.endswith('::hydrogen') & lab.str.contains('electrolyzer')\n",
    "    )\n",
    "\n",
    "    # Electricidad consumida por electrólisis\n",
    "    elec_to_e_ts = _series_time(\n",
    "        da_con, 'loc_tech_carriers_con',\n",
    "        lambda lab: lab.str.endswith('::electricity') & lab.str.contains('electrolyzer')\n",
    "    ).pipe(lambda x: xr.apply_ufunc(np.abs, x))\n",
    "\n",
    "    # Agua consumida por electrólisis (si existe)\n",
    "    if (da_con['loc_tech_carriers_con'].to_pandas().astype(str).str.endswith('::water').any()):\n",
    "        water_to_e_ts = _series_time(\n",
    "            da_con, 'loc_tech_carriers_con',\n",
    "            lambda lab: lab.str.endswith('::water') & lab.str.contains('electrolyzer')\n",
    "        ).pipe(lambda x: xr.apply_ufunc(np.abs, x))\n",
    "    else:\n",
    "        water_to_e_ts = xr.zeros_like(h2_served_ts)\n",
    "\n",
    "    # Storage SoC agregado (si existe variable 'storage')\n",
    "    if 'storage' in ds:\n",
    "        storage_ts = ds.storage.sum(dim=[d for d in ds.storage.dims if d != 'timesteps'])\n",
    "    else:\n",
    "        storage_ts = xr.zeros_like(h2_served_ts)\n",
    "\n",
    "    # --- Capacidades (estáticas) ---\n",
    "    cap_pv   = _energy_cap(ds, r'::pv$')\n",
    "    cap_el   = _energy_cap(ds, r'electrolyzer')\n",
    "    cap_line = _energy_cap(ds, r'ac_line')\n",
    "    cap_h2st = _storage_cap(ds, r'h2_store')\n",
    "\n",
    "    # --- Costos agregados (estáticos al horizonte) ---\n",
    "    total_cost = float(ds.cost.sum()) if 'cost' in ds else np.nan\n",
    "\n",
    "    # --- Construcción de ventanas ---\n",
    "    t = ds['timesteps']\n",
    "    nT = t.sizes['timesteps']\n",
    "    slices = _window_slices(nT, WINDOW_HOURS, STEP_HOURS)\n",
    "\n",
    "    rows = []\n",
    "    for (a, b) in slices:\n",
    "        # recortes\n",
    "        sl = slice(a, b)\n",
    "        _h2_serv   = float(h2_served_ts.isel(timesteps=sl).sum())\n",
    "        _h2_prod   = float(h2_prod_ts.isel(timesteps=sl).sum())\n",
    "        _elec_e    = float(elec_to_e_ts.isel(timesteps=sl).sum())\n",
    "        _water_e   = float(water_to_e_ts.isel(timesteps=sl).sum())\n",
    "        _soc_min   = float(storage_ts.isel(timesteps=sl).min())\n",
    "        _soc_p50   = float(storage_ts.isel(timesteps=sl).quantile(0.5))\n",
    "        _soc_p95   = float(storage_ts.isel(timesteps=sl).quantile(0.95))\n",
    "\n",
    "        # proxies útiles\n",
    "        demand_proxy = _h2_serv  # si tienes serie de demanda objetivo separada, cámbiala aquí\n",
    "        unmet = max(0.0, 0.0 - (_h2_serv - demand_proxy))  # placeholder si no tienes demanda explícita\n",
    "\n",
    "        # ratios\n",
    "        sp_h2   = _h2_prod / (_elec_e + EPS)                  # eficiencia específica H2/kWh_elec\n",
    "        water_h2= _water_e / (_h2_prod + EPS)                 # agua por MWh_H2\n",
    "\n",
    "        # CF electrolizador aproximado por ventana (si hay cap_el)\n",
    "        cf_el = (_h2_prod / (cap_el * (b - a) + EPS)) if cap_el > 0 else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            # --- targets/proxies de resiliencia (medibles por ventana) ---\n",
    "            \"h2_served_MWh\": _h2_serv,\n",
    "            \"h2_unmet_proxy\": unmet,\n",
    "            \"soc_min\": _soc_min,\n",
    "            \"soc_p50\": _soc_p50,\n",
    "            \"soc_p95\": _soc_p95,\n",
    "\n",
    "            # --- performance/uso ---\n",
    "            \"h2_produced_MWh\": _h2_prod,\n",
    "            \"elec_to_e_MWh\": _elec_e,\n",
    "            \"water_to_e_units\": _water_e,\n",
    "            \"sp_h2_MWh_per_MWh_elec\": sp_h2,\n",
    "            \"water_per_MWh_h2\": water_h2,\n",
    "            \"cf_electrolyzer_approx\": cf_el,\n",
    "\n",
    "            # --- capacidades estáticas (replicadas en cada ventana) ---\n",
    "            \"cap_pv_MW\": cap_pv,\n",
    "            \"cap_el_MW\": cap_el,\n",
    "            \"cap_line_MW\": cap_line,\n",
    "            \"cap_h2_store_MWh\": cap_h2st,\n",
    "\n",
    "            # --- costos agregados (horizonte) ---\n",
    "            \"total_cost\": total_cost,\n",
    "\n",
    "            # --- metadatos ---\n",
    "            \"t_start_idx\": a,\n",
    "            \"t_end_idx\": b\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # -------- NORMALIZACIÓN SENCILLA --------\n",
    "    # (ajústala a tus necesidades; aquí dejamos escalas razonables para arrancar)\n",
    "    scale_by = df[[\"h2_served_MWh\", \"h2_produced_MWh\"]].quantile(0.95).max()\n",
    "    scale_by = float(scale_by) if np.isfinite(scale_by) and scale_by > 0 else 1.0\n",
    "\n",
    "    for col in [\"h2_served_MWh\",\"h2_produced_MWh\",\"elec_to_e_MWh\",\"cap_pv_MW\",\n",
    "                \"cap_el_MW\",\"cap_line_MW\",\"cap_h2_store_MWh\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col] / (scale_by + EPS)\n",
    "\n",
    "    # Guardar\n",
    "    df.to_parquet(out_parquet, index=False)\n",
    "    print(f\"[OK] Ventanas guardadas en {out_parquet} | shape={df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20923586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Ventanas guardadas en resilience/windows.parquet | shape=(243, 18)\n"
     ]
    }
   ],
   "source": [
    "nc_path = \"results_baseline_2028_tx.nc\"\n",
    "out_path = \"resilience/windows.parquet\"\n",
    "\n",
    "build_windows(nc_path, out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
