{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02c119c",
   "metadata": {},
   "source": [
    "# An√°lisis de Compatibilidad de Datos CMIP6 y CR2MET\n",
    "## Valle de Aconcagua, Chile\n",
    "\n",
    "Pipeline para bias correction usando Quantile Mapping. Empezamos con un an√°lisis sistem√°tico de los datasets para entender su estructura y compatibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b19498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports completados\n",
      "‚úì xarray version: 2025.1.2\n",
      "‚úì numpy version: 2.2.3\n",
      "‚úì pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "# Imports b√°sicos para an√°lisis de datos\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Imports completados\")\n",
    "print(f\"‚úì xarray version: {xr.__version__}\")\n",
    "print(f\"‚úì numpy version: {np.__version__}\")\n",
    "print(f\"‚úì pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3971023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuraci√≥n completada\n",
      "‚úì CMIP6 path: /home/aninotna/magister/tesis/justh2_pipeline/data/cmip6/historical\n",
      "‚úì CR2MET path: /home/aninotna/magister/tesis/justh2_pipeline/data/cr2met/clima.zarr\n",
      "‚úì Regi√≥n Valle de Aconcagua: {'lat_min': -33.27, 'lat_max': -32.26, 'lon_min': -71.89, 'lon_max': -70.0}\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de paths\n",
    "BASE_PATH = Path(\"/home/aninotna/magister/tesis/justh2_pipeline\")\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "CMIP6_PATH = DATA_PATH / \"cmip6\" / \"historical\"\n",
    "CR2MET_PATH = DATA_PATH / \"cr2met\" / \"clima.zarr\"\n",
    "\n",
    "# Regi√≥n Valle de Aconcagua\n",
    "BBOX = {\n",
    "    'lat_min': -33.27,\n",
    "    'lat_max': -32.26, \n",
    "    'lon_min': -71.89,\n",
    "    'lon_max': -70.00\n",
    "}\n",
    "\n",
    "print(\"‚úì Configuraci√≥n completada\")\n",
    "print(f\"‚úì CMIP6 path: {CMIP6_PATH}\")\n",
    "print(f\"‚úì CR2MET path: {CR2MET_PATH}\")\n",
    "print(f\"‚úì Regi√≥n Valle de Aconcagua: {BBOX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15262b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ANALIZANDO DATASET CR2MET\n",
      "========================================\n",
      "‚úì CR2MET cargado exitosamente\n",
      "\n",
      "üìä INFORMACI√ìN GENERAL:\n",
      "  Variables: ['year', 'cl_mask', 'pr', 'tmin', 'pr_sd', 'tmax']\n",
      "  Dimensiones: {'time': 22646, 'lat': 800, 'lon': 220}\n",
      "  Coordenadas: ['lat', 'time', 'lon']\n",
      "\n",
      "üó∫Ô∏è INFORMACI√ìN ESPACIAL:\n",
      "  Latitud: -56.975 a -17.025\n",
      "  Longitud: -76.975 a -66.025\n",
      "  Resoluci√≥n lat: ~0.050¬∞\n",
      "  Resoluci√≥n lon: ~0.050¬∞\n",
      "\n",
      "‚è∞ INFORMACI√ìN TEMPORAL:\n",
      "  Per√≠odo: 1960-01-01T00:00:00.000000000 a 2021-12-31T00:00:00.000000000\n",
      "  Total d√≠as: 22646\n",
      "  Frecuencia: 1 d√≠a(s)\n",
      "\n",
      "üåßÔ∏è PRECIPITACI√ìN (PR):\n",
      "  Shape: (22646, 800, 220)\n",
      "  Unidades: mm/day\n"
     ]
    }
   ],
   "source": [
    "# 1. AN√ÅLISIS DE CR2MET\n",
    "print(\"üîç ANALIZANDO DATASET CR2MET\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Cargar CR2MET\n",
    "    cr2met = xr.open_dataset(CR2MET_PATH)\n",
    "    print(f\"‚úì CR2MET cargado exitosamente\")\n",
    "    \n",
    "    # Informaci√≥n b√°sica\n",
    "    print(f\"\\nüìä INFORMACI√ìN GENERAL:\")\n",
    "    print(f\"  Variables: {list(cr2met.data_vars)}\")\n",
    "    print(f\"  Dimensiones: {dict(cr2met.dims)}\")\n",
    "    print(f\"  Coordenadas: {list(cr2met.coords)}\")\n",
    "    \n",
    "    # Informaci√≥n espacial\n",
    "    print(f\"\\nüó∫Ô∏è INFORMACI√ìN ESPACIAL:\")\n",
    "    print(f\"  Latitud: {cr2met.lat.values.min():.3f} a {cr2met.lat.values.max():.3f}\")\n",
    "    print(f\"  Longitud: {cr2met.lon.values.min():.3f} a {cr2met.lon.values.max():.3f}\")\n",
    "    print(f\"  Resoluci√≥n lat: ~{np.diff(cr2met.lat.values)[0]:.3f}¬∞\")\n",
    "    print(f\"  Resoluci√≥n lon: ~{np.diff(cr2met.lon.values)[0]:.3f}¬∞\")\n",
    "    \n",
    "    # Informaci√≥n temporal\n",
    "    print(f\"\\n‚è∞ INFORMACI√ìN TEMPORAL:\")\n",
    "    print(f\"  Per√≠odo: {cr2met.time.values[0]} a {cr2met.time.values[-1]}\")\n",
    "    print(f\"  Total d√≠as: {len(cr2met.time)}\")\n",
    "    time_diff = pd.to_datetime(cr2met.time.values[1]) - pd.to_datetime(cr2met.time.values[0])\n",
    "    print(f\"  Frecuencia: {time_diff.days} d√≠a(s)\")\n",
    "    \n",
    "    # An√°lisis de precipitaci√≥n\n",
    "    if 'pr' in cr2met.data_vars:\n",
    "        pr = cr2met['pr']\n",
    "        print(f\"\\nüåßÔ∏è PRECIPITACI√ìN (PR):\")\n",
    "        print(f\"  Shape: {pr.shape}\")\n",
    "        print(f\"  Unidades: {pr.attrs.get('units', 'No especificadas')}\")\n",
    "        print(f\"  Min: {float(pr.min().values):.3f}\")\n",
    "        print(f\"  Max: {float(pr.max().values):.3f}\")\n",
    "        print(f\"  Media: {float(pr.mean().values):.3f}\")\n",
    "        \n",
    "        # Recorte al Valle de Aconcagua\n",
    "        pr_valle = pr.sel(\n",
    "            lat=slice(BBOX['lat_min'], BBOX['lat_max']),\n",
    "            lon=slice(BBOX['lon_min'], BBOX['lon_max'])\n",
    "        )\n",
    "        print(f\"\\n‚úÇÔ∏è RECORTE VALLE DE ACONCAGUA:\")\n",
    "        print(f\"  Shape: {pr_valle.shape}\")\n",
    "        print(f\"  Rango lat: {pr_valle.lat.values.min():.3f} a {pr_valle.lat.values.max():.3f}\")\n",
    "        print(f\"  Rango lon: {pr_valle.lon.values.min():.3f} a {pr_valle.lon.values.max():.3f}\")\n",
    "        print(f\"  Media regional: {float(pr_valle.mean().values):.3f}\")\n",
    "        \n",
    "        # Guardar para an√°lisis posterior\n",
    "        cr2met_pr_valle = pr_valle\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Variable 'pr' no encontrada en CR2MET\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando CR2MET: {e}\")\n",
    "    \n",
    "print(f\"\\n‚úÖ An√°lisis CR2MET completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d624073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. AN√ÅLISIS DE ARCHIVOS CMIP6\n",
    "print(\"üîç ANALIZANDO ARCHIVOS CMIP6\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Listar archivos disponibles\n",
    "pr_path = CMIP6_PATH / \"pr\"\n",
    "if pr_path.exists():\n",
    "    archivos = list(pr_path.glob(\"*.nc\"))\n",
    "    print(f\"üìÅ Archivos encontrados: {len(archivos)}\")\n",
    "    \n",
    "    for archivo in sorted(archivos):\n",
    "        print(f\"  - {archivo.name} ({archivo.stat().st_size / (1024**3):.2f} GB)\")\n",
    "        \n",
    "    # Analizar primer archivo como ejemplo\n",
    "    if archivos:\n",
    "        archivo_ejemplo = archivos[0]\n",
    "        print(f\"\\nüî¨ AN√ÅLISIS DETALLADO: {archivo_ejemplo.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Intentar cargar con diferentes engines\n",
    "            for engine in ['netcdf4', 'h5netcdf', 'scipy']:\n",
    "                try:\n",
    "                    ds = xr.open_dataset(archivo_ejemplo, engine=engine)\n",
    "                    print(f\"  ‚úì Archivo cargado exitosamente con engine: {engine}\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ùå Engine {engine} fall√≥: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if 'ds' in locals():\n",
    "                # Informaci√≥n general\n",
    "                print(f\"\\nüìä INFORMACI√ìN GENERAL:\")\n",
    "                print(f\"  Variables: {list(ds.data_vars)}\")\n",
    "                print(f\"  Dimensiones: {dict(ds.dims)}\")\n",
    "                print(f\"  Coordenadas: {list(ds.coords)}\")\n",
    "                \n",
    "                # Informaci√≥n espacial\n",
    "                print(f\"\\nüó∫Ô∏è INFORMACI√ìN ESPACIAL:\")\n",
    "                print(f\"  Latitud: {ds.lat.values.min():.3f} a {ds.lat.values.max():.3f}\")\n",
    "                print(f\"  Longitud: {ds.lon.values.min():.3f} a {ds.lon.values.max():.3f}\")\n",
    "                \n",
    "                # Verificar si necesita conversi√≥n de coordenadas (0-360 -> -180-180)\n",
    "                if ds.lon.values.max() > 180:\n",
    "                    print(f\"  ‚ö†Ô∏è Coordenadas en formato 0-360¬∞, necesita conversi√≥n a -180-180¬∞\")\n",
    "                else:\n",
    "                    print(f\"  ‚úì Coordenadas ya en formato -180-180¬∞\")\n",
    "                \n",
    "                # Informaci√≥n temporal\n",
    "                print(f\"\\n‚è∞ INFORMACI√ìN TEMPORAL:\")\n",
    "                print(f\"  Per√≠odo: {ds.time.values[0]} a {ds.time.values[-1]}\")\n",
    "                print(f\"  Total timesteps: {len(ds.time)}\")\n",
    "                if len(ds.time) > 1:\n",
    "                    time_diff = pd.to_datetime(ds.time.values[1]) - pd.to_datetime(ds.time.values[0])\n",
    "                    print(f\"  Frecuencia: {time_diff.days} d√≠a(s)\")\n",
    "                \n",
    "                # An√°lisis de precipitaci√≥n\n",
    "                if 'pr' in ds.data_vars:\n",
    "                    pr_cmip = ds['pr']\n",
    "                    print(f\"\\nüåßÔ∏è PRECIPITACI√ìN (PR):\")\n",
    "                    print(f\"  Shape: {pr_cmip.shape}\")\n",
    "                    print(f\"  Unidades: {pr_cmip.attrs.get('units', 'No especificadas')}\")\n",
    "                    print(f\"  Dtype: {pr_cmip.dtype}\")\n",
    "                    \n",
    "                    # Estad√≠sticos b√°sicos (muestra peque√±a para evitar problemas de memoria)\n",
    "                    sample = pr_cmip.isel(time=slice(0, 10))\n",
    "                    print(f\"  Min (muestra): {float(sample.min().values):.6f}\")\n",
    "                    print(f\"  Max (muestra): {float(sample.max().values):.6f}\")\n",
    "                    print(f\"  Media (muestra): {float(sample.mean().values):.6f}\")\n",
    "                    \n",
    "                    # Verificar traslape espacial con Valle de Aconcagua\n",
    "                    lat_overlap = (ds.lat.values >= BBOX['lat_min']) & (ds.lat.values <= BBOX['lat_max'])\n",
    "                    \n",
    "                    # Ajustar longitudes si es necesario\n",
    "                    if ds.lon.values.max() > 180:\n",
    "                        lon_adjusted = ((ds.lon.values + 180) % 360) - 180\n",
    "                        lon_overlap = (lon_adjusted >= BBOX['lon_min']) & (lon_adjusted <= BBOX['lon_max'])\n",
    "                    else:\n",
    "                        lon_overlap = (ds.lon.values >= BBOX['lon_min']) & (ds.lon.values <= BBOX['lon_max'])\n",
    "                    \n",
    "                    print(f\"\\nüéØ TRASLAPE CON VALLE DE ACONCAGUA:\")\n",
    "                    print(f\"  Pixeles latitud en regi√≥n: {lat_overlap.sum()}\")\n",
    "                    print(f\"  Pixeles longitud en regi√≥n: {lon_overlap.sum()}\")\n",
    "                    \n",
    "                    if lat_overlap.sum() > 0 and lon_overlap.sum() > 0:\n",
    "                        print(f\"  ‚úì Hay traslape espacial con la regi√≥n\")\n",
    "                    else:\n",
    "                        print(f\"  ‚ùå No hay traslape espacial con la regi√≥n\")\n",
    "                \n",
    "                # Cerrar dataset\n",
    "                ds.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error analizando archivo: {e}\")\n",
    "            \n",
    "else:\n",
    "    print(f\"‚ùå Directorio {pr_path} no existe\")\n",
    "    \n",
    "print(f\"\\n‚úÖ An√°lisis CMIP6 completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867adea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. AN√ÅLISIS DE COMPATIBILIDAD TEMPORAL\n",
    "print(\"üîç AN√ÅLISIS DE COMPATIBILIDAD TEMPORAL\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if 'cr2met' in locals() and 'ds' in locals():\n",
    "    # Per√≠odos temporales\n",
    "    cr2_start = pd.to_datetime(cr2met.time.values[0])\n",
    "    cr2_end = pd.to_datetime(cr2met.time.values[-1])\n",
    "    \n",
    "    # Reabrir dataset CMIP6 para an√°lisis temporal\n",
    "    archivo_ejemplo = list((CMIP6_PATH / \"pr\").glob(\"*.nc\"))[0]\n",
    "    ds_temp = xr.open_dataset(archivo_ejemplo, engine='netcdf4')\n",
    "    \n",
    "    cmip_start = pd.to_datetime(ds_temp.time.values[0])\n",
    "    cmip_end = pd.to_datetime(ds_temp.time.values[-1])\n",
    "    \n",
    "    print(f\"üìÖ PER√çODOS TEMPORALES:\")\n",
    "    print(f\"  CR2MET: {cr2_start.strftime('%Y-%m-%d')} a {cr2_end.strftime('%Y-%m-%d')} ({(cr2_end - cr2_start).days} d√≠as)\")\n",
    "    print(f\"  CMIP6:  {cmip_start.strftime('%Y-%m-%d')} a {cmip_end.strftime('%Y-%m-%d')} ({(cmip_end - cmip_start).days} d√≠as)\")\n",
    "    \n",
    "    # Calcular traslape\n",
    "    overlap_start = max(cr2_start, cmip_start)\n",
    "    overlap_end = min(cr2_end, cmip_end)\n",
    "    \n",
    "    if overlap_start <= overlap_end:\n",
    "        overlap_days = (overlap_end - overlap_start).days\n",
    "        print(f\"\\n‚úÖ TRASLAPE TEMPORAL:\")\n",
    "        print(f\"  Per√≠odo: {overlap_start.strftime('%Y-%m-%d')} a {overlap_end.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"  Duraci√≥n: {overlap_days} d√≠as ({overlap_days/365.25:.1f} a√±os)\")\n",
    "        \n",
    "        # Evaluar idoneidad para bias correction\n",
    "        if overlap_days >= 365 * 10:  # Al menos 10 a√±os\n",
    "            print(f\"  ‚úì Suficiente para bias correction (>10 a√±os)\")\n",
    "        elif overlap_days >= 365 * 5:  # Al menos 5 a√±os\n",
    "            print(f\"  ‚ö†Ô∏è Marginal para bias correction (5-10 a√±os)\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Insuficiente para bias correction (<5 a√±os)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå NO HAY TRASLAPE TEMPORAL\")\n",
    "    \n",
    "    ds_temp.close()\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Datasets no cargados, no se puede analizar compatibilidad temporal\")\n",
    "    \n",
    "print(f\"\\n‚úÖ An√°lisis de compatibilidad temporal completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. RESUMEN Y RECOMENDACIONES\n",
    "print(\"üìã RESUMEN Y RECOMENDACIONES PARA BIAS CORRECTION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(f\"\\nüéØ DATASETS IDENTIFICADOS:\")\n",
    "print(f\"  ‚úì CR2MET: Datos de referencia observacional\")\n",
    "print(f\"  ‚úì CMIP6: Datos de modelo clim√°tico (ACCESS-CM2)\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è PASOS NECESARIOS PARA COMPATIBILIZACI√ìN:\")\n",
    "print(f\"  1. üó∫Ô∏è Regridding espacial: CMIP6 ‚Üí CR2MET grid\")\n",
    "print(f\"  2. ‚è∞ Alineaci√≥n temporal: encontrar per√≠odo de traslape\")\n",
    "print(f\"  3. üîß Estandarizaci√≥n de unidades: kg/m¬≤/s ‚Üí mm/d√≠a\")\n",
    "print(f\"  4. üìÖ Alineaci√≥n de calendarios: manejar a√±os bisiestos\")\n",
    "print(f\"  5. üåßÔ∏è Wet-day adjustment: manejar d√≠as secos en precipitaci√≥n\")\n",
    "\n",
    "print(f\"\\nüîß M√âTODOS DE BIAS CORRECTION RECOMENDADOS:\")\n",
    "print(f\"  ‚Ä¢ Empirical Quantile Mapping (EQM): M√©todo est√°ndar\")\n",
    "print(f\"  ‚Ä¢ Detrended Quantile Mapping (DQM): Para preservar tendencias\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è CONSIDERACIONES IMPORTANTES:\")\n",
    "print(f\"  ‚Ä¢ Resoluci√≥n espacial muy diferente (CMIP6 vs CR2MET)\")\n",
    "print(f\"  ‚Ä¢ Verificar conversi√≥n de coordenadas 0-360¬∞ ‚Üí -180-180¬∞\")\n",
    "print(f\"  ‚Ä¢ Manejar chunks de dask para datasets grandes\")\n",
    "print(f\"  ‚Ä¢ Validar resultados en per√≠odo de entrenamiento\")\n",
    "\n",
    "print(f\"\\nüöÄ PR√ìXIMO PASO:\")\n",
    "print(f\"  Implementar pipeline de compatibilizaci√≥n paso a paso\")\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lisis de compatibilidad completado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
